{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from astropy.io.fits import getdata\n",
    "from astropy import units as u\n",
    "from astropy.coordinates import SkyCoord, Angle\n",
    "from astroquery.vizier import Vizier\n",
    "from astropy.table import Table\n",
    "from astroquery.xmatch import XMatch\n",
    "import time\n",
    "\n",
    "import sys  \n",
    "sys.path.insert(0, '../')\n",
    "#sys.path.insert(0, '/Users/yanghui/Desktop/Research/2019/MUWCLASS_Project/ML/ML_pipelines_merge/MUWCLASS_pipeline_github/MUWCLASS/')\n",
    "#from muwclass import datasets, prep, red,  classify, distribution, plots, prepare_data, prepare_cxo\n",
    "\n",
    "from prepare_library import atnf_pos, create_perobs_data, cal_ave, add_MW, confusion_clean, TD_clean\n",
    "from muwclass_library import prepare_cols\n",
    "\n",
    "Vizier.ROW_LIMIT = -1\n",
    "exnum = -999999."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './data'\n",
    "field_name = 'CSC_TD'\n",
    "# 11122021: not removing stars without MW counterparts, not using PU = max(sep, PU)\n",
    "verb = 0\n",
    "\n",
    "#query_dir = '/Users/yanghui/Desktop/Research/2019/MUWCLASS_Project/ML/DATA/TD/query'\n",
    "query_dir = '../demo/data/query'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YSOs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3419 Counter({'D': 2991, 'P': 428})\n",
      "808 Counter({'II': 478, '0/I': 247, 'III': 83})\n",
      "72 Counter({'II': 26, '': 22, 'III': 17, 'I': 7})\n",
      "56 Counter({'II': 20, 'III': 16, 'I/II': 9, 'I': 9, 'II/III': 2})\n",
      "272 Counter({'k': 178, 'n': 94})\n",
      "308 Counter({2: 308})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: UnitsWarning: Unit 'Msun' not supported by the VOUnit standard.  [astropy.units.format.vounit]\n",
      "WARNING: UnitsWarning: The unit 'ct' has been deprecated in the VOUnit standard. [astropy.units.format.utils]\n",
      "WARNING: UnitsWarning: The unit 'ct' has been deprecated in the VOUnit standard. [astropy.units.format.utils]\n"
     ]
    }
   ],
   "source": [
    "YSO1 = Vizier(catalog=\"J/AJ/144/192\",row_limit=-1,\n",
    "    columns=['*', '_RAJ2000', '_DEJ2000']).query_constraints(Cl='=|P|D')[0]\n",
    "YSO1 = YSO1['_RAJ2000','_DEJ2000','Cl'].to_pandas().rename(columns={'Cl':'SubClass'})\n",
    "YSO1['e_Pos'], YSO1['ref'] = np.nan, '2012AJ....144..192M'\n",
    "print(len(YSO1),Counter(YSO1['SubClass']))\n",
    "\n",
    "YSO2 = Vizier(catalog=\"J/ApJS/194/14/catalog\",row_limit=-1,\n",
    "    columns=['*', '_RAJ2000', '_DEJ2000']).query_constraints(Stage='!=A')[0]\n",
    "YSO2 = YSO2['_RAJ2000','_DEJ2000','Stage'].to_pandas().rename(columns={'Stage':'SubClass'})\n",
    "YSO2['e_Pos'], YSO2['ref'] = np.nan, '2011ApJS..194...14P'\n",
    "print(len(YSO2),Counter(YSO2['SubClass']))\n",
    "\n",
    "\n",
    "YSO3 = Vizier(catalog=\"J/A+A/429/963\",row_limit=-1,\n",
    "    columns=['*', '_RAJ2000', '_DEJ2000','e_Pos']).query_constraints(Class='!=nIII')[0]\n",
    "YSO3 = YSO3['_RAJ2000','_DEJ2000','e_Pos','Class'].to_pandas().rename(columns={'Class':'SubClass'})\n",
    "YSO3['ref'] = '2005A&A...429..963O'\n",
    "print(len(YSO3),Counter(YSO3['SubClass']))\n",
    "\n",
    "\n",
    "YSO4 = Vizier(catalog=\"J/A%2bA/463/275/table5\",row_limit=-1,\n",
    "    columns=['*', '_RAJ2000', '_DEJ2000']).query_constraints(clYSO='=|I|I/II|II|II/III|III')[0]\n",
    "YSO4 = YSO4['_RAJ2000','_DEJ2000','clYSO'].to_pandas().rename(columns={'clYSO':'SubClass'})\n",
    "YSO4['e_Pos'], YSO4['ref'] = np.nan, '2007A&A...463..275G'\n",
    "print(len(YSO4),Counter(YSO4['SubClass']))\n",
    "\n",
    "YSO5 = Vizier(catalog=\"J/ApJS/196/4\",row_limit=-1,\n",
    "    columns=['*', '_RAJ2000', '_DEJ2000']).query_constraints(St='=|k|n')[0]\n",
    "YSO5 = YSO5['_RAJ2000','_DEJ2000','St'].to_pandas().rename(columns={'St':'SubClass'})\n",
    "YSO5['e_Pos'], YSO5['ref'] = np.nan,  '2011ApJS..196....4R'\n",
    "print(len(YSO5),Counter(YSO5['SubClass']))\n",
    "\n",
    "YSO6 = Vizier(catalog=\"J/A%2bA/531/A141/catalog\",row_limit=-1,\n",
    "    columns=['*', '_RAJ2000', '_DEJ2000']).query_constraints(MmD='=2')[0]\n",
    "YSO6 = YSO6['_RAJ2000','_DEJ2000','MmD'].to_pandas().rename(columns={'MmD':'SubClass'})\n",
    "YSO6['e_Pos'], YSO6['ref'] = np.nan, '2011A&A...531A.141D'\n",
    "print(len(YSO6),Counter(YSO6['SubClass']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4935 YSOs\n"
     ]
    }
   ],
   "source": [
    "df_YSOs = pd.concat([YSO1, YSO2, YSO3, YSO4, YSO5, YSO6])\n",
    "df_YSOs = df_YSOs.reset_index(drop=True)\n",
    "df_YSOs['Class']='YSO'\n",
    "print(len(df_YSOs),'YSOs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STARs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "937000\n"
     ]
    }
   ],
   "source": [
    "stars = Vizier(catalog=\"B/mk/mktypes\",row_limit=-1,\n",
    "    columns=['*', '_RAJ2000', '_DEJ2000']).query_constraints(Mag='<=23')[0]\n",
    "stars = stars['_RAJ2000','_DEJ2000','Name','SpType','Bibcode','Remarks','Mag'].to_pandas()\n",
    "stars = stars.replace(r'^\\s*$', np.nan, regex=True)\n",
    "print(len(stars)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "937000\n",
      "238222\n",
      "622683\n",
      "69952\n",
      "516991\n",
      "692\n",
      "516182\n"
     ]
    }
   ],
   "source": [
    "stars_d1 = stars[stars['SpType'].str.contains('e|s|n|p|f|cv|i|r|a|D|C|cont|l|H|h|abs|\\+|\\*|\\:|\\?', na=False)]\n",
    "stars_f1 = stars[~stars.set_index(['_RAJ2000','_DEJ2000']).index.isin(stars_d1.set_index(['_RAJ2000','_DEJ2000']).index)]\n",
    "stars_f1 = stars_f1.reset_index(drop=True)\n",
    "\n",
    "print(len(stars))\n",
    "print(len(stars_d1))\n",
    "print(len(stars_f1))\n",
    "\n",
    "\n",
    "stars_d2 = stars_f1[stars_f1['Remarks'].isnull() == False]\n",
    "stars_f2 = stars_f1[~stars_f1.set_index(['_RAJ2000','_DEJ2000']).index.isin(stars_d2.set_index(['_RAJ2000','_DEJ2000']).index)]\n",
    "stars_f2 = stars_f2.reset_index(drop=True)\n",
    "\n",
    "print(len(stars_d2))\n",
    "print(len(stars_f2))\n",
    "\n",
    "\n",
    "stars_d3 = stars_f2[stars_f2['Name'].str.contains('H97b')]\n",
    "stars_f3 = stars_f2[~stars_f2.set_index(['_RAJ2000','_DEJ2000']).index.isin(stars_d3.set_index(['_RAJ2000','_DEJ2000']).index)]\n",
    "stars_f3 = stars_f3.reset_index(drop=True)\n",
    "\n",
    "print(len(stars_d3))\n",
    "print(len(stars_f3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62124\n",
      "450224\n"
     ]
    }
   ],
   "source": [
    "\n",
    "star_hm = stars_f3[stars_f3['SpType'].str.startswith(tuple(['O','B','W']), na=False)]\n",
    "star_lm = stars_f3[stars_f3['SpType'].str.startswith(tuple(['A','F','G','K','M']), na=False)]\n",
    "star_hm = star_hm.reset_index(drop=True)\n",
    "star_lm = star_lm.reset_index(drop=True)\n",
    "\n",
    "star_hm['e_Pos'], star_hm['Class'] = np.nan, 'HM-STAR'\n",
    "star_lm['e_Pos'], star_lm['Class'] = np.nan, 'LM-STAR'\n",
    "df_HMSTARs = star_hm.rename(columns={'Name':'name_cat','SpType':'SubClass','Bibcode':'ref'}).drop(columns=['Remarks','Mag'])\n",
    "df_LMSTARs = star_lm.rename(columns={'Name':'name_cat','SpType':'SubClass','Bibcode':'ref'}).drop(columns=['Remarks','Mag'])\n",
    "print(len(df_HMSTARs))\n",
    "print(len(df_LMSTARs))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310171\n"
     ]
    }
   ],
   "source": [
    "APOGEE_all = Vizier(catalog=\"III/284/allstars\",row_limit=-1,\n",
    "    columns=['*','_RAJ2000', '_DEJ2000','AName','Giant','Star']).query_constraints(Teff='>3000 & <10000',logg='>-1 & <7')[0]\n",
    "\n",
    "APOGEE = APOGEE_all['_RAJ2000','_DEJ2000','AName','Giant','Star','TClass','Teff','logg','s_HRV','errHRV'].to_pandas()\n",
    "\n",
    "#APOGEE_STAR = APOGEE[(APOGEE.s_HRV <= 1) & (APOGEE.s_HRV <= 5*APOGEE.errHRV)].reset_index(drop=True)# & APOGEE.Teff.isnull() & (APOGEE.logg <= 7) & (APOGEE.logg >= -1) ]\n",
    "\n",
    "APOGEE_STAR = APOGEE[(APOGEE.s_HRV <= 1) & (APOGEE.s_HRV <= 5*APOGEE.errHRV) & (APOGEE.Star == 1)].reset_index(drop=True)# & APOGEE.Teff.isnull() & (APOGEE.logg <= 7) & (APOGEE.logg >= -1) ]\n",
    "\n",
    "APOGEE_STAR['e_Pos'], APOGEE_STAR['Class'], APOGEE_STAR['ref'] = np.nan, 'LM-STAR', '2020AJ....160..120J'\n",
    "APOGEE_STAR = APOGEE_STAR.rename(columns={'AName':'name_cat','TClass':'SubClass'})\n",
    "APOGEE_STAR = APOGEE_STAR.replace('none', np.nan, regex=True)\n",
    "APOGEE_STAR = APOGEE_STAR.drop(columns=['Giant','Star','Teff','logg','s_HRV','errHRV'])\n",
    "print(len(APOGEE_STAR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WRs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226\n"
     ]
    }
   ],
   "source": [
    "WRs1 = Vizier(catalog=\"III/215\",row_limit=-1,\n",
    "    columns=['*', '_RAJ2000', '_DEJ2000','OName']).query_constraints()[0]\n",
    "WRs1 = WRs1['_RAJ2000','_DEJ2000','Name','OName','Aname'].to_pandas()\n",
    "WRs1['Class'], WRs1['e_Pos'], WRs1['ref'], WRs1['SubClass'] = 'HM-STAR', np.nan, '2001NewAR..45..135V', np.nan#III/215\n",
    "WRs1 = WRs1.replace(r'^\\s*$', np.nan, regex=True)\n",
    "WRs1['name_cat'] = WRs1['Name'].combine_first(WRs1['OName'].combine_first(WRs1['Aname']))\n",
    "df_WRs1 = WRs1.drop(columns=['Name','OName','Aname'])\n",
    "print(len(df_WRs1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118\n"
     ]
    }
   ],
   "source": [
    "WRs2 = Vizier(catalog=\"J/A+A/458/453/table1\",row_limit=-1,\n",
    "    columns=['*', '_RAJ2000', '_DEJ2000']).query_constraints()[0]\n",
    "WRs2 = WRs2['_RAJ2000','_DEJ2000','SpType','SpType0','SimbadName','WRori'].to_pandas()\n",
    "WRs2['Class'], WRs2['e_Pos'], WRs2['ref']= 'HM-STAR', np.nan, '2006A&A...458..453V'#J/A+A/458/453/table1\n",
    "WRs2 = WRs2.replace(r'^\\s*$', np.nan, regex=True)\n",
    "WRs2['name_cat'] = WRs2['SimbadName'].combine_first(WRs2['WRori'])\n",
    "WRs2['SubClass'] = WRs2['SpType'].combine_first(WRs2['SpType0'])\n",
    "df_WRs2 = WRs2.drop(columns=['SpType','SpType0','SimbadName','WRori'])\n",
    "print(len(df_WRs2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quasars & AGNs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168940 Counter({'Q': 133335, 'A': 34231, 'B': 1374})\n"
     ]
    }
   ],
   "source": [
    "AGNs = Vizier(catalog=\"VII/258/vv10\",row_limit=-1,\n",
    "    columns=['*', '_RAJ2000', '_DEJ2000']).query_constraints(Cl='|Q|A|B')[0]\n",
    "AGNs = AGNs['_RAJ2000','_DEJ2000','Name','Cl'].to_pandas()\n",
    "AGNs['Class'], AGNs['e_Pos'], AGNs['ref']= 'AGN', np.nan, '2010A&A...518A..10V'#VII/258/vv10\n",
    "df_AGNs = AGNs.rename(columns={'Name':'name_cat','Cl':'SubClass'})\n",
    "\n",
    "print(len(df_AGNs), Counter(df_AGNs['SubClass']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HMXBs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114\n"
     ]
    }
   ],
   "source": [
    "HMXBs = Vizier(catalog=\"J/A+A/455/1165/table1\",row_limit=-1,\n",
    "    columns=['*', '_RAJ2000', '_DEJ2000']).query_constraints()[0]\n",
    "HMXBs = HMXBs['_RAJ2000','_DEJ2000','Name','Type'].to_pandas()\n",
    "HMXBs['Class'], HMXBs['e_Pos'], HMXBs['ref'] = 'HMXB', np.nan, '2006A&A...455.1165L'#J/A+A/455/1165/table1\n",
    "df_HMXBs = HMXBs.rename(columns={'Name':'name_cat','Type':'SubClass'})\n",
    "print(len(df_HMXBs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LMXBs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187\n"
     ]
    }
   ],
   "source": [
    "LMXBs1 = Vizier(catalog=\"J/A+A/469/807\",row_limit=-1,\n",
    "    columns=['*', '_RAJ2000', '_DEJ2000']).query_constraints()[0]\n",
    "LMXBs1 = LMXBs1['_RAJ2000','_DEJ2000','Name','Type'].to_pandas()\n",
    "LMXBs1['Class'], LMXBs1['e_Pos'], LMXBs1['ref'] = 'LMXB', np.nan, '2007A&A...469..807L'#J/A+A/469/807\n",
    "df_LMXBs1 = LMXBs1.rename(columns={'Name':'name_cat','Type':'SubClass'})\n",
    "print(len(df_LMXBs1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108\n"
     ]
    }
   ],
   "source": [
    "LMXBs2 = Vizier(catalog=\"B/cb/lmxbdata\",row_limit=-1,\n",
    "    columns=['*', '_RAJ2000', '_DEJ2000','epos']).query_constraints()[0]\n",
    "\n",
    "#'''\n",
    "LMXBs2 = LMXBs2['_RAJ2000','_DEJ2000','epos','Name','Type1'].to_pandas()\n",
    "LMXBs2['Class'], LMXBs2['ref'] = 'LMXB', '2003A&A...404..301R' #B/cb/lmxbdata\n",
    "df_LMXBs2 = LMXBs2.rename(columns={'Name':'name_cat','Type1':'SubClass','epos':'e_Pos'})\n",
    "print(len(df_LMXBs2))\n",
    "#'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1618\n"
     ]
    }
   ],
   "source": [
    "CVs1 = Vizier(catalog=\"V/123A\",row_limit=-1,\n",
    "    columns=['*', '_RAJ2000', '_DEJ2000']).query_constraints()[0]\n",
    "CVs1 = CVs1['_RAJ2000','_DEJ2000','Names','VarType'].to_pandas()\n",
    "CVs1['Class'], CVs1['e_Pos'], CVs1['ref'] = 'CV', np.nan, '2005JAD....11....2D'#'2001PASP..113..764D'#V/123A\n",
    "CVs1 = CVs1[CVs1['VarType']!='non-CV'].reset_index(drop=True)\n",
    "df_CVs1 = CVs1.rename(columns={'Names':'name_cat','VarType':'SubClass'})\n",
    "print(len(df_CVs1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1429\n"
     ]
    }
   ],
   "source": [
    "CVs2 = Vizier(catalog=\"B/cb/cbdata\",row_limit=-1,\n",
    "    columns=['*', '_RAJ2000', '_DEJ2000','epos']).query_constraints()[0]\n",
    "CVs2 = CVs2['_RAJ2000','_DEJ2000','epos','Name','Type1'].to_pandas()\n",
    "CVs2['Class'], CVs2['ref'] = 'CV', '2003A&A...404..301R'#B/cb/cbdata\n",
    "df_CVs2 = CVs2.rename(columns={'Name':'name_cat','Type1':'SubClass','epos':'e_Pos'})\n",
    "print(len(df_CVs2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NS & NS_BIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3177 Counter({' ': 2844, 'ELL1': 143, 'BT': 107, 'DD': 39, 'DDH': 14, 'ELL1H': 10, 'BTX': 7, 'DDGR': 4, 'T2': 3, 'MSS': 3, 'DDS': 1, 'BT2P': 1, 'DDK': 1})\n",
      "             NAME Binary   Class\n",
      "6      J0023+0923   ELL1  NS_BIN\n",
      "60     J0101-6422     BT  NS_BIN\n",
      "313   J0737-3039B     DD  NS_BIN\n",
      "560    J1124-3653             NS\n",
      "644    J1231-1411     BT  NS_BIN\n",
      "714    J1311-3430   ELL1  NS_BIN\n",
      "921    J1514-4946   ELL1  NS_BIN\n",
      "984      B1534+12     DD  NS_BIN\n",
      "1107   J1614-2230  ELL1H  NS_BIN\n",
      "1172   J1628-3205     BT  NS_BIN\n",
      "1294   J1653-0158   ELL1  NS_BIN\n",
      "1494   J1731-1847    BTX  NS_BIN\n",
      "1836   J1810+1744     BT  NS_BIN\n",
      "1881   J1816+4510   ELL1  NS_BIN\n",
      "2545   J1909-3744   ELL1  NS_BIN\n",
      "2909     B1957+20     BT  NS_BIN\n",
      "2953   J2017+0603  ELL1H  NS_BIN\n",
      "3002   J2043+1711   ELL1  NS_BIN\n",
      "3013   J2047+1053     BT  NS_BIN\n",
      "3018   J2051-0827   ELL1  NS_BIN\n",
      "3100   J2214+3000   ELL1  NS_BIN\n",
      "3102   J2215+5135   ELL1  NS_BIN\n",
      "3106   J2222-0137     DD  NS_BIN\n",
      "3125   J2241-5236     BT  NS_BIN\n",
      "3133   J2256-1024    BTX  NS_BIN\n",
      "3167   J2339-0533   ELL1  NS_BIN\n",
      "3177\n",
      "3177 Counter({'NS': 2844, 'NS_BIN': 333})\n"
     ]
    }
   ],
   "source": [
    "import urllib3\n",
    "\n",
    "http = urllib3.PoolManager()\n",
    "r = http.request('GET', 'https://www.atnf.csiro.au/research/pulsar/psrcat/proc_form.php?version=1.65&Name=Name&RaJ=RaJ&DecJ=DecJ&Binary=Binary&Type=Type&startUserDefined=true&c1_val=&c2_val=&c3_val=&c4_val=&sort_attr=jname&sort_order=asc&condition=&pulsar_names=&ephemeris=short&coords_unit=raj%2Fdecj&radius=&coords_1=&coords_2=&style=Long+csv+with+errors&no_value=*&fsize=3&x_axis=&x_scale=linear&y_axis=&y_scale=linear&state=query&table_bottom.x=35&table_bottom.y=15') # it's a file like object and works just like a file\n",
    "r.status\n",
    "\n",
    "ATNF = r.data.decode('utf-8').partition('\\n<pre>\\n')[2].partition('\\n</pre>\\n')[0].replace('*',' ').split('\\n')\n",
    "#print(ATNF)\n",
    "#ATNF = str(r.data).partition('\\\\n<pre>\\\\n')[2].partition('\\\\n</pre>\\\\n')[0]\n",
    "\n",
    "NSs = pd.DataFrame(columns=['src', 'NAME','Name_ref','RAJ','e_RA','RAJ_ref','DECJ','e_DEC','DECJ_ref','Binary','Binary_ref','PSR_type','Type_ref'], \n",
    "                data=[row.split(';') for row in ATNF[2:]])\n",
    "#NSs = pd.DataFrame(ATNF)\n",
    "#NSs = pd.read_csv(ATNF, sep=';',lineterminator='\\n' )\n",
    "#print(NSs)\n",
    "NSs['_RAJ2000'] = NSs.apply(lambda row: atnf_pos(row.RAJ, row.e_RA, 'hms', 'pos'), axis=1)\n",
    "NSs['_e_RAJ2000'] = NSs.apply(lambda row: atnf_pos(row.RAJ, row.e_RA, 'hms', 'err'), axis=1)\n",
    "NSs['_DEJ2000'] = NSs.apply(lambda row: atnf_pos(row.DECJ, row.e_DEC, 'dms', 'pos'), axis=1)\n",
    "NSs['_e_DEJ2000'] = NSs.apply(lambda row: atnf_pos(row.DECJ, row.e_DEC, 'dms', 'err'), axis=1)\n",
    "#print(NSs[['_e_RAJ2000','_e_DEJ2000']])\n",
    "NSs['e_Pos'] = NSs.apply(lambda row: max(row._e_RAJ2000 , row._e_DEJ2000), axis=1)\n",
    "\n",
    "#'''\n",
    "NSs.loc[NSs.NAME=='J1819-1458', '_RAJ2000'] = 274.8924\n",
    "NSs.loc[NSs.NAME=='J1819-1458', '_DEJ2000'] = -14.9676579999999\n",
    "NSs.loc[NSs.NAME=='J1741-2054', '_RAJ2000'] = 265.48868\n",
    "NSs.loc[NSs.NAME=='J1741-2054', '_DEJ2000'] = -20.903278\n",
    "#'''\n",
    "\n",
    "NSs['ref']= '2005AJ....129.1993M'#B/psr/psr\n",
    "NSs['Class'] = 'NS_BIN'\n",
    "print(len(NSs),Counter(NSs['Binary']))\n",
    "NSs.loc[NSs['Binary']==' ', 'Class'] = 'NS'\n",
    "\n",
    "\n",
    "new_NS_BINs = pd.read_csv(f'{data_dir}/new_NS_BIN.csv')\n",
    "print(NSs.loc[NSs.NAME.isin(new_NS_BINs.name_cat.values), ['NAME','Binary','Class']])\n",
    "#print(NSs.loc[NSs.NAME.isin(['J0437-4715']), ['NAME','Binary','Class']])\n",
    "\n",
    "df_NSs = NSs[['NAME','_RAJ2000','_DEJ2000','e_Pos','Class','PSR_type','ref']].rename(columns={'NAME':'name_cat','PSR_type':'SubClass'})\n",
    "print(len(df_NSs))\n",
    "\n",
    "print(len(df_NSs),Counter(df_NSs['Class']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HMXBs, LMXBs, and CVs from INTEGRAL General Reference Catalog (IGRS) and HMXBs from Be Star catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bestar = pd.read_csv('/Users/yanghui/Desktop/Research/2020/Proposal/XMM/BeSS_Epsilon/master_Simbad.csv')\n",
    "HMXB_Be = Bestar[Bestar['main_type'].str.contains('HMXB', na=False)].drop_duplicates(subset=['main_id'])[['main_id','ra_Simbad','dec_Simbad','type']]\n",
    "df_HMXB_Be = HMXB_Be.rename(columns={'main_id':'name_cat','ra_Simbad':'_RAJ2000','dec_Simbad':'_DEJ2000','type':'SubClass'})\n",
    "df_HMXB_Be['Class'], df_HMXB_Be['e_Pos'], df_HMXB_Be['ref'] = 'HMXB', np.nan, 'Simbad'\n",
    "df_HMXB_Be = df_HMXB_Be.reset_index(drop=True)\n",
    "print(len(df_HMXB_Be))\n",
    "df_HMXB_Be.to_csv('/Users/yanghui/Desktop/Research/2019/MUWCLASS_Project/ML/DATA/TD/MoreSources/HMXBBeStar/HMXBBeStar.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IGRS = pd.read_csv('/Users/yanghui/Desktop/Research/2019/MUWCLASS_Project/ML/DATA/TD/versions/CSC_TD_v4.csv')[3466:].reset_index(drop=True)[['name_cat','ra_cat','dec_cat','error','Class','SubClass']]\n",
    "IGRS['ref'] = 'INTEGRAL General Reference Catalog'\n",
    "df_IGRS = IGRS.rename(columns={'ra_cat':'_RAJ2000','dec_cat':'_DEJ2000','error':'e_Pos'})\n",
    "print(len(df_IGRS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'HMXB': 55, 'LMXB': 8, 'CV': 5})\n"
     ]
    }
   ],
   "source": [
    "df_HMXB_Be = pd.read_csv(f'{data_dir}/raretype_BeStar_IGRS.csv')\n",
    "print(Counter(df_HMXB_Be['Class']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining sources together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_TD = pd.concat([df_AGNs, df_YSOs, df_LMSTARs, APOGEE_STAR, df_HMSTARs, df_WRs1, df_WRs2, df_NSs, df_HMXBs, df_LMXBs1, df_LMXBs2, df_CVs1, df_CVs2, df_HMXB_Be], ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_RAJ2000</th>\n",
       "      <th>_DEJ2000</th>\n",
       "      <th>name_cat</th>\n",
       "      <th>SubClass</th>\n",
       "      <th>Class</th>\n",
       "      <th>e_Pos</th>\n",
       "      <th>ref</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005417</td>\n",
       "      <td>-2.033333</td>\n",
       "      <td>FIRST J00000-0202</td>\n",
       "      <td>Q</td>\n",
       "      <td>AGN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010A&amp;A...518A..10V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005833</td>\n",
       "      <td>-30.607500</td>\n",
       "      <td>2QZ J000001-3036</td>\n",
       "      <td>Q</td>\n",
       "      <td>AGN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010A&amp;A...518A..10V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.007083</td>\n",
       "      <td>-31.373889</td>\n",
       "      <td>2QZ J000001-3122</td>\n",
       "      <td>Q</td>\n",
       "      <td>AGN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010A&amp;A...518A..10V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.011250</td>\n",
       "      <td>-25.193611</td>\n",
       "      <td>XMM J00000-2511</td>\n",
       "      <td>Q</td>\n",
       "      <td>AGN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010A&amp;A...518A..10V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.011667</td>\n",
       "      <td>-35.059167</td>\n",
       "      <td>MS 23574-3520</td>\n",
       "      <td>Q</td>\n",
       "      <td>AGN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2010A&amp;A...518A..10V</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   _RAJ2000   _DEJ2000           name_cat SubClass Class e_Pos  \\\n",
       "0  0.005417  -2.033333  FIRST J00000-0202        Q   AGN   NaN   \n",
       "1  0.005833 -30.607500   2QZ J000001-3036        Q   AGN   NaN   \n",
       "2  0.007083 -31.373889   2QZ J000001-3122        Q   AGN   NaN   \n",
       "3  0.011250 -25.193611    XMM J00000-2511        Q   AGN   NaN   \n",
       "4  0.011667 -35.059167      MS 23574-3520        Q   AGN   NaN   \n",
       "\n",
       "                   ref  \n",
       "0  2010A&A...518A..10V  \n",
       "1  2010A&A...518A..10V  \n",
       "2  2010A&A...518A..10V  \n",
       "3  2010A&A...518A..10V  \n",
       "4  2010A&A...518A..10V  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_TD.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1003439 [('AGN', 168940), ('CV', 3052), ('HM-STAR', 62468), ('HMXB', 169), ('LM-STAR', 760395), ('LMXB', 303), ('NS', 2844), ('NS_BIN', 333), ('YSO', 4935)]\n"
     ]
    }
   ],
   "source": [
    "print(len(df_TD), sorted(Counter(df_TD['Class']).items()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11331 [('AGN', 6174), ('CV', 342), ('HM-STAR', 895), ('HMXB', 77), ('LM-STAR', 1862), ('LMXB', 166), ('NS', 222), ('NS_BIN', 148), ('YSO', 1445)]\n"
     ]
    }
   ],
   "source": [
    "# matching with CSCv2\n",
    "\n",
    "TD_CSC = XMatch.query(cat1= Table.from_pandas(df_TD), #open('/Users/yanghui/Desktop/Research/2019/MUWCLASS_Project/ML/DATA/TD/versions/CSC_TD_v5_09062021.csv'),\n",
    "                      cat2='vizier:IX/57/csc2master',\n",
    "                      max_distance=3*u.arcsec, colRA1='_RAJ2000',colDec1='_DEJ2000')\n",
    "\n",
    "TD_CSC = TD_CSC.to_pandas()\n",
    "print(len(TD_CSC), sorted(Counter(TD_CSC['Class']).items()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "TD_CSC.head(5)\n",
    "\n",
    "TD_CSC.to_csv(f'{data_dir}/{field_name}_Xmatch_all.csv',index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10723 [('AGN', 5978), ('CV', 275), ('HM-STAR', 767), ('HMXB', 68), ('LM-STAR', 1834), ('LMXB', 139), ('NS', 165), ('NS_BIN', 90), ('YSO', 1407)]\n"
     ]
    }
   ],
   "source": [
    "TD_CSC = pd.read_csv(f'{data_dir}/{field_name}_Xmatch_all.csv')\n",
    "\n",
    "TD_CSC = TD_CSC.sort_values(by=['angDist']) \n",
    "#print(TD_CSC[TD_CSC.duplicated(subset=['_RAJ2000_1', '_DEJ2000_1', 'name_cat', 'SubClass', 'Class','e_Pos', 'ref'])])\n",
    "TD_CSC = TD_CSC.drop_duplicates(subset=['_RAJ2000_1', '_DEJ2000_1', 'name_cat', 'SubClass', 'Class','e_Pos', 'ref']).reset_index(drop=True)\n",
    "\n",
    "print(len(TD_CSC), sorted(Counter(TD_CSC['Class']).items()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#Table.from_pandas(df)\n",
    "TD_CSC = XMatch.query(cat1= Table.from_pandas(df_TD), #open('/Users/yanghui/Desktop/Research/2019/MUWCLASS_Project/ML/DATA/TD/versions/CSC_TD_v5_09062021.csv'),\n",
    "                      cat2='vizier:IX/57/csc2master',\n",
    "                      max_distance=2*u.arcsec, colRA1='_RAJ2000',colDec1='_DEJ2000')\n",
    "\n",
    "TD_CSC = TD_CSC.to_pandas()\n",
    "print(len(TD_CSC), sorted(Counter(TD_CSC['Class']).items()))\n",
    "\n",
    "8815 [('AGN', 5549), ('CV', 183), ('HM-STAR', 343), ('HMXB', 75), ('LM-STAR', 864), ('LMXB', 77), ('NS', 162), ('NS_BIN', 89), ('WR', 92), ('YSO', 1381)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove 6440 [('AGN', 4485), ('HM-STAR', 364), ('LM-STAR', 1108), ('YSO', 483)]\n",
      "4283 [('AGN', 1493), ('CV', 275), ('HM-STAR', 403), ('HMXB', 68), ('LM-STAR', 726), ('LMXB', 139), ('NS', 165), ('NS_BIN', 90), ('YSO', 924)]\n"
     ]
    }
   ],
   "source": [
    "TD_CSC['PU'] = np.sqrt(TD_CSC.e_Pos.fillna(0)*2**2+TD_CSC.r0.fillna(0)**2)\n",
    "\n",
    "TD_CSC['name'] = TD_CSC.apply(lambda row: '2CXO '+str(row['2CXO']),axis=1)\n",
    "\n",
    "#TD_CSC.to_csv(f'{data_dir}/TD_check_all.csv',index=False)\n",
    "\n",
    "idx = np.where( ((TD_CSC['angDist']>TD_CSC['PU']) | (TD_CSC['PU'] >1.) )& ((TD_CSC['Class']=='AGN') | (TD_CSC['Class']=='YSO') | (TD_CSC['Class']=='HM-STAR') | (TD_CSC['Class']=='LM-STAR') ))[0]\n",
    "print('Remove', len(idx), sorted(Counter(TD_CSC.loc[idx, 'Class']).items()))\n",
    "TD_CSC = TD_CSC.drop(TD_CSC.index[idx])\n",
    "TD_CSC = TD_CSC.reset_index(drop=True)\n",
    "print(len(TD_CSC), sorted(Counter(TD_CSC['Class']).items()))\n",
    "\n",
    "TD = TD_CSC.rename(columns={'_RAJ2000_1':'ra_cat','_DEJ2000_1':'dec_cat','angDist':'sep','RAICRS':'ra','DEICRS':'dec'})[['name_cat','ra_cat','dec_cat','e_Pos','Class','SubClass','ref','sep','name','ra','dec','r0','PU']].sort_values(by=['Class','ra']).reset_index(drop=True)\n",
    "\n",
    "\n",
    "TD['remove_code'] = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4105\n",
      "Index(['name_cat', 'ra_cat', 'dec_cat', 'e_Pos', 'Class', 'SubClass', 'ref',\n",
      "       'sep', 'name', 'ra', 'dec', 'r0', 'PU', 'remove_code', '_r_simbad',\n",
      "       'main_id', 'ra_simbad', 'dec_simbad', 'coo_err_maj', 'coo_err_min',\n",
      "       'coo_err_angle', 'nbref', 'ra_sexa', 'dec_sexa', 'coo_qual',\n",
      "       'coo_bibcode', 'main_type', 'other_types', 'radvel', 'radvel_err',\n",
      "       'redshift', 'redshift_err', 'sp_type', 'morph_type', 'plx', 'plx_err',\n",
      "       'pmra', 'pmdec', 'pm_err_maj', 'pm_err_min', 'pm_err_pa', 'size_maj',\n",
      "       'size_min', 'size_angle', 'B', 'V', 'R', 'J', 'H', 'K'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "TD_simbad = XMatch.query(cat1=Table.from_pandas(TD),\n",
    "                         cat2='vizier:SIMBAD',max_distance=3 * u.arcsec, colRA1='ra',colDec1='dec')\n",
    "TD_simbad = TD_simbad.to_pandas().rename(columns={'ra_1':'ra', 'dec_1':'dec','ra_2':'ra_simbad', 'dec_2':'dec_simbad', 'angDist':'_r_simbad'}).sort_values(by=['_r_simbad']) \n",
    "TD_simbad = TD_simbad.drop_duplicates(subset=['name_cat','ra_cat','dec_cat','Class','name'], keep='first').reset_index(drop=True)\n",
    "print(len(TD_simbad))\n",
    "TD= pd.merge(TD, TD_simbad, how='outer', on = ['name_cat','ra_cat','dec_cat','e_Pos','Class','SubClass','ref', 'sep', 'name', 'ra', 'dec', 'r0','PU','remove_code'])\n",
    "\n",
    "TD.loc[TD.name_cat.isnull(), 'name_cat'] = TD.loc[TD.name_cat.isnull(), 'main_id']\n",
    "TD.loc[TD.name_cat.isnull(), 'name_cat'] = TD.loc[TD.name_cat.isnull(), 'name']\n",
    "print(TD.columns[:50])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "move2YSOs = [ '[DWS84] 20','HJM C 1-25','HJM C 5-3','[HAD2004] NGC 1579 210','[HAD2004] NGC 1579 260',\n",
    "    'MBO 66','MBO 62','MB045','Cl* NGC 2024 LSE 12','Cl* NGC 2024 LSE 3','Cl* NGC 2024 LSE 6',\n",
    "    'Cl* NGC 2024 LSE 16','Cl* NGC 2024 LSE 2','[CCE98] 42','[CFB2003] Par-Lup3-2','ASR 107','ASR 43',\n",
    "    'ASR 36','[PNJ2003] 7']\n",
    "print(len(move2YSOs))\n",
    "s = np.where(TD.name_cat.isin(move2YSOs))[0]\n",
    "\n",
    "TD.loc[s, :].to_csv(f'{data_dir}/{field_name}_YSO_clean.csv',index=False)\n",
    "\n",
    "src2YSO = ['MBO 62']\n",
    "#s = np.where((TD['name_cat'].isin(src2YSO)))[0]# | (TD['ref']=='2004ApJ...610.1045S') )[0] #& (TD['name_cat'].str.contains('PNJ')))[0]\n",
    "#s = np.where( (TD['ref']=='2004ApJ...610.1045S') )[0] #& (TD['name_cat'].str.contains('PNJ')))[0]\n",
    "s = np.where(((TD['main_type'].str.contains('Orion_V*|TTau*|YSO')) & (TD['Class']!='YSO')))[0]\n",
    "\n",
    "'''\n",
    "ra_Orion = (5+(35+17.3/60)/60)*15\n",
    "dec_Orion = (-1)*(5+(23+28/60)/60)\n",
    "TD['sep_Orion'] = TD.apply(lambda row: SkyCoord(row.ra*u.deg, row.dec*u.deg, frame='icrs').separation(SkyCoord(ra_Orion*u.deg, dec_Orion*u.deg, frame='icrs')).arcsec, axis=1)\n",
    "s = np.where((TD['sep_Orion']<180) & (TD['Class']!='YSO'))[0]\n",
    "'''\n",
    "#print(Counter(TD.loc[s, 'main_type']))\n",
    "print(TD.loc[s, :])\n",
    "\n",
    "#TD.loc[s, :].to_csv(f'{data_dir}/{field_name}_YSO_clean.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting [('HM-STAR', 91), ('LM-STAR', 290)] sources to YSOs.\n",
      "4283 [('AGN', 1493), ('CV', 275), ('HM-STAR', 312), ('HMXB', 68), ('LM-STAR', 436), ('LMXB', 139), ('NS', 165), ('NS_BIN', 90), ('YSO', 1305)]\n"
     ]
    }
   ],
   "source": [
    "## Re-assign those STARs which are actually YSOs \n",
    "src2YSO = ['MBO 62']\n",
    "s = np.where(((TD['main_type'].str.contains('Orion_V*|TTau*|YSO')) & (TD['Class']!='YSO')) | (TD['name_cat'].isin(src2YSO)) | (TD['ref']=='2004ApJ...610.1045S') )[0] #& (TD['name_cat'].str.contains('PNJ')))[0]\n",
    "print(\"Converting\", sorted(Counter(TD['Class'][s]).items()), \"sources to YSOs.\")\n",
    "TD.loc[s, 'Class'] = 'YSO'\n",
    "print(len(TD), sorted(Counter(TD['Class']).items()))\n",
    "\n",
    "#  check the remaining stars if they can still be YSOs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           name_cat   Class\n",
      "2225  XTE J1858+034    HMXB\n",
      "3152     J1124-3653      NS\n",
      "3287    J0737-3039B  NS_BIN\n",
      "3292       B1259-63  NS_BIN\n",
      "3297       B1534+12  NS_BIN\n",
      "3349     J2032+4127  NS_BIN\n",
      "           name_cat   Class\n",
      "2225  XTE J1858+034    LMXB\n",
      "3152     J1124-3653  NS_BIN\n",
      "3287    J0737-3039B      NS\n",
      "3292       B1259-63    HMXB\n",
      "3297       B1534+12      NS\n",
      "3349     J2032+4127    HMXB\n"
     ]
    }
   ],
   "source": [
    "print(TD.loc[TD.name_cat.isin(['B1259-63','J1124-3653','J2032+4127','XTE J1858+034','J0737-3039B','B1534+12']), ['name_cat','Class']])\n",
    "\n",
    "TD.loc[TD.name_cat=='B1259-63', 'Class'] = 'HMXB'\n",
    "TD.loc[TD.name_cat=='J1124-3653', 'Class'] = 'NS_BIN'\n",
    "TD.loc[TD.name_cat=='J2032+4127', 'Class'] = 'HMXB'\n",
    "TD.loc[TD.name_cat=='XTE J1858+034', 'Class'] = 'LMXB'\n",
    "\n",
    "double_NSs = ['J0737-3039B', 'B1534+12']\n",
    "TD.loc[TD.name_cat.isin(double_NSs), 'Class'] = 'NS'\n",
    "\n",
    "print(TD.loc[TD.name_cat.isin(['B1259-63','J1124-3653','J2032+4127','XTE J1858+034','J0737-3039B','B1534+12']), ['name_cat','Class']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# There are sources matched to the same CSC sources due to\n",
    "# 1. those sources are the same sources with the same classes from different literatures/sources (updated tables)\n",
    "# 2. those sources are the same sources with different classifications from different sources\n",
    "# 3. the same CSC sources are matched to different sources due to confusion\n",
    "# we will keep the first case with the nearest counterpart while throwing the 2nd & 3rd cases\n",
    "print(\"remove code = 2 duplicate CSC sources\")\n",
    "\n",
    "TD_dup = TD[TD.duplicated(subset=['name'], keep=False)].sort_values(by=['name'])\n",
    "\n",
    "\n",
    "s_all = []\n",
    "for name in TD_dup.name.unique():\n",
    "    df_s = TD[TD['name']==name]\n",
    "    df_s = df_s.reset_index(drop=True)\n",
    "    if len(df_s)!=2:\n",
    "        s = np.where(TD['name']==name)[0]\n",
    "        s_all = np.append(s_all, s)\n",
    "    else:\n",
    "        df_s1 = df_s.iloc[0]\n",
    "        df_s2 = df_s.iloc[1]\n",
    "        if df_s1['Class'] != df_s2['Class']:\n",
    "            s = np.where(TD['name']==name)[0]\n",
    "            s_all = np.append(s_all, s)\n",
    "        else:\n",
    "            sep_max = max(df_s['sep'])\n",
    "            s = np.where( (TD['name']==name) & (TD['sep']==sep_max))[0]\n",
    "            if len(s)==2:\n",
    "                s_all = np.append(s_all, s[0])\n",
    "                #print(s)\n",
    "            else:\n",
    "                s_all = np.append(s_all, s)\n",
    "\n",
    "TD.loc[s_all, 'remove_code'] = TD.loc[s_all, 'remove_code']+2\n",
    "print('Remove', len(s_all), sorted(Counter(TD.loc[s_all, 'Class']).items()))\n",
    "TD.loc[s_all, :].to_csv(f'{data_dir}/{field_name}_remove_code2.csv',index=False)\n",
    "print('Left', len(TD[TD['remove_code']==0]), sorted(Counter(TD[TD['remove_code']==0]['Class']).items()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove code = 2 duplicate CSC sources\n",
      "Remove 609 [('CV', 78), ('HM-STAR', 156), ('HMXB', 9), ('LM-STAR', 113), ('LMXB', 44), ('NS', 32), ('NS_BIN', 35), ('YSO', 142)]\n",
      "Left 3674 [('AGN', 1493), ('CV', 197), ('HM-STAR', 156), ('HMXB', 60), ('LM-STAR', 323), ('LMXB', 96), ('NS', 134), ('NS_BIN', 52), ('YSO', 1163)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Different LVSs matched to the same CSC sources:\n",
    "# 1. if different LVSs with the same classification are matched the same CSCv2 source, the nearest LVS is remained. \n",
    "# 2. if CSCv2 sources are matched to LVSs with different classifications, the X-ray sources will be removed. \n",
    "print(\"remove code = 2 duplicate CSC sources\")\n",
    "\n",
    "TD_dup = TD[TD.duplicated(subset=['name'], keep=False)].sort_values(by=['name'])\n",
    "\n",
    "\n",
    "s_all = []\n",
    "for name in TD_dup.name.unique():\n",
    "    df_s = TD[TD['name']==name]\n",
    "    df_s = df_s.reset_index(drop=True)\n",
    "    if len(df_s['Class'].unique()) >1:\n",
    "        s = np.where(TD['name']==name)[0]\n",
    "        s_all = np.append(s_all, s)\n",
    "    else:\n",
    "        \n",
    "        sep_min = min(df_s['sep'])\n",
    "        s_src = np.where(TD['name']==name)[0]\n",
    "        s_min = np.where( (TD['name']==name) & (TD['sep']==sep_min))[0]\n",
    "        \n",
    "        if len(s_min)>1:\n",
    "            s_all = np.append(s_all, list(set(s_src) - set([s_min[0]])))\n",
    "        else:\n",
    "            s_all = np.append(s_all, list(set(s_src) - set(s_min)))\n",
    "        \n",
    "\n",
    "TD.loc[s_all, 'remove_code'] = TD.loc[s_all, 'remove_code']+2\n",
    "print('Remove', len(s_all), sorted(Counter(TD.loc[s_all, 'Class']).items()))\n",
    "TD.loc[s_all, :].to_csv(f'{data_dir}/{field_name}_remove_code2_2.csv',index=False)\n",
    "print('Left', len(TD[TD['remove_code']==0]), sorted(Counter(TD[TD['remove_code']==0]['Class']).items()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove_code = 4: sources in crowded/complex environments\n",
      "0.41849780082702637\n"
     ]
    }
   ],
   "source": [
    "print(\"remove_code = 4: sources in crowded/complex environments\")\n",
    "viz = Vizier(row_limit=-1,  timeout=5000, columns=[\"**\", \"+_r\"], catalog=\"J/A+A/558/A53/catalog\",column_filters={\"Type\":\"g\"},)\n",
    "\n",
    "radec = [[TD.loc[i, 'ra'], TD.loc[i, 'dec']] for i in range(len(TD))]\n",
    "rd = Table(Angle(radec, 'deg'), names=('_RAJ2000', '_DEJ2000'))\n",
    "\n",
    "start = time.time()\n",
    "query_res = viz.query_region(rd, radius=1.*u.deg)[0]\n",
    "df_gc = query_res.to_pandas()\n",
    "df_gc = df_gc[df_gc._r < df_gc.r2].reset_index(drop=True)\n",
    "df_gc['_q_index'] = df_gc['_q']-1\n",
    "end = time.time() \n",
    "print(end - start)\n",
    "\n",
    "TD['remove_4'] = 0\n",
    "TD.loc[TD.index.isin(df_gc._q_index), 'remove_4'] = TD.loc[TD.index.isin(df_gc._q_index), 'remove_4'] +1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "TD['Gal_Long'] = TD.apply(lambda row: SkyCoord(ra=row.ra*u.degree, dec=row.dec*u.degree, frame='icrs').galactic.l.degree, axis=1)\n",
    "\n",
    "TD['Gal_Lat'] =  TD.apply(lambda row: SkyCoord(ra=row.ra*u.degree, dec=row.dec*u.degree, frame='icrs').galactic.b.degree, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove 659 [('AGN', 9), ('CV', 181), ('HM-STAR', 67), ('HMXB', 15), ('LM-STAR', 79), ('LMXB', 55), ('NS', 64), ('NS_BIN', 59), ('YSO', 130)]\n",
      "Left 3216 [('AGN', 1484), ('CV', 58), ('HM-STAR', 121), ('HMXB', 45), ('LM-STAR', 266), ('LMXB', 58), ('NS', 101), ('NS_BIN', 25), ('YSO', 1058)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#          LMC,      SMC,  Westerlund 1, M31, NGC 300, NGC 3379, Liller 1,NGC 6791, M 27/NGC 6853, Circinus Galaxy, NGC 2264, IC 348, NGC 1333      \n",
    "re_ras =[80.89375, 13.1867, 251.76667,10.68458,13.7229,161.95666,263.3520,290.22083,299.901417, 213.29125,        100.25,  56.13833, 52.2971]\n",
    "re_decs=[-69.75611,-72.8286,-45.85136,41.26916,-37.6844,12.58163,-33.3889,37.771667,22.721136, -65.339167,        9.8833,  32.16333, 31.31]\n",
    "re_rs  =[10.75,    5.33,    3./60,    1.,      0.17,     0.04,   0.003,   16./60,  8./60,     6.9/60,             45./60,  42./60,   6./60]\n",
    "### 2002AJ....123.1528R 2003ApJ...593.1093L 1994A&AS..106..165A for NGC 2264, IC 348, NGC 1333    \n",
    "\n",
    "for ra, dec, r in zip(re_ras, re_decs, re_rs):\n",
    "    #print(ra, dec, r)\n",
    "    TD['remove_4'] = TD.apply(lambda row: row.remove_4 +1 if SkyCoord(row.ra*u.deg, row.dec*u.deg, frame='icrs').separation(SkyCoord(ra*u.deg, dec*u.deg, frame='icrs')).deg < r else row.remove_4,axis=1)\n",
    "\n",
    "# crowded Galactic Center\n",
    "#idx = np.where((TD.ra>266.38) & (TD.ra<266.59) & (TD.dec>-29.1) & (TD.dec<-28.5) & (TD.Class!='LM-STAR'))[0]\n",
    "idx = np.where(((TD.Gal_Long > 350.) | (TD.Gal_Long < 10.)) & (TD.Gal_Lat>-5.) & (TD.Gal_Lat<5.))[0]# & (TD.Class!='LM-STAR'))[0]\n",
    "TD.loc[idx, 'remove_4'] = TD.loc[idx, 'remove_4']+1\n",
    "\n",
    "idx = np.where((TD['name'].str.strip().str[-1].str.isalpha()) & (~TD['name'].isin(['2CXO J043715.9-471509X'])))[0]\n",
    "TD.loc[idx, 'remove_4'] = TD.loc[idx, 'remove_4'] + 1\n",
    "\n",
    "# drop sources (mostly NSs) in complex exvironment, in bright PWNe \n",
    "SN_delete = ['2CXO J151355.6-590809','2CXO J174715.8-295801','2CXO J183333.5-103407','2CXO J053747.4-691019','2CXO J083520.6-451034','2CXO J195258.2+325240','2CXO J054010.8-691954','2CXO J090835.4-491305','2CXO J180150.6-085733','2CXO J184343.3-040805','2CXO J102347.6+003840','2CXO J174615.5-321400','2CXO J163905.4-464212']\n",
    "#Oleg Check ['PSR J0540-6919  ','PSR J0908-4913  ','PSR J1748-2446C ','PSR J1748-2021A ','PSR J1801-0857C ','PSR J1843-0408  ','PSR J2129+1210A '] and has been removed\n",
    "# 2CXO J163905.4-464212 (HMXB) drop due to its confused counterpart\n",
    "\n",
    "# LMXBs and HMXBs that appeared in the previous TD and most of them are in the crowded environment but since they appeared in the \n",
    "# previous TD so they have gone through manual investigation so should be fine to add\n",
    "LMXBs_HMXBs_save = ['2CXO J174819.2-360716', '2CXO J180632.1-221417', '2CXO J181044.4-260901', '2CXO J174502.3-285449', \n",
    "              '2CXO J174702.5-285259', '2CXO J173413.4-260518', '2CXO J174931.7-280805', '2CXO J173953.9-282946',\n",
    "              '2CXO J174433.0-284426', '2CXO J174354.8-294443',  '2CXO J171419.7-340246','2CXO J174451.1-292116', \n",
    "              '2CXO J181921.6-252425', '2CXO J174621.1-284343', # LMXB so far\n",
    "              '2CXO J173527.5-325554', '2CXO J175834.5-212321', '2CXO J174445.7-271344'] # HMXBs\n",
    "\n",
    "\n",
    "s = np.where(((TD['remove_4']>0) | (TD.name.isin(SN_delete))) & (~TD.name.isin(LMXBs_HMXBs_save)) )[0]\n",
    "TD.loc[s, 'remove_code'] = TD.loc[s, 'remove_code'] + 4\n",
    "\n",
    "print('Remove', len(s), sorted(Counter(TD.loc[s, 'Class']).items()))\n",
    "print('Left', len(TD[TD['remove_code']==0]), sorted(Counter(TD[TD['remove_code']==0]['Class']).items()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TD[(TD['remove_code']==4) & ((TD.Class =='HMXB') | (TD.Class =='LMXB'))].to_csv('TD_crowd.csv',index=False)\n",
    "\n",
    "#TD.loc[(TD['remove_code']==4) & ((TD.Class =='HMXB') | (TD.Class =='LMXB')), 'remove_code'] = 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "s_all = []\n",
    "\n",
    "for name in TD_dup.name.unique():\n",
    "    df_s = TD[TD['name']==name]\n",
    "    df_s = df_s.reset_index(drop=True)\n",
    "    if len(df_s)!=2:\n",
    "        s = np.where(TD['name']==name)[0]\n",
    "        s_all = np.append(s_all, s)\n",
    "    else:\n",
    "        df_s1 = df_s.iloc[0]\n",
    "        df_s2 = df_s.iloc[1]\n",
    "        if df_s1['Class'] != df_s2['Class']:\n",
    "            s = np.where(TD['name']==name)[0]\n",
    "            s_all = np.append(s_all, s)\n",
    "\n",
    "#TD[(TD.index.isin(s_all))].to_csv(f'{data_dir}/TD_check_dup.csv',index=False)\n",
    "            \n",
    "#TD[(TD.index.isin(s_all)) & (TD['remove_code']==2)].to_csv('TD_check_dup.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "src_delete = ['[DWS84] 20', 'HD 38563 C', '[RHI84] 10- 632', '[HC2000] 114','[CHG2008] C2-18','Cl* NGC 2244 John 14','V* V2361 Ori','V* V1129 Cen','HD 35914','M 51 X-7','1E 161348-5055.1','XTE J1829-098']\n",
    "#print(len(src_delete))\n",
    "#s = np.where(TD.name_cat.isin(src_delete))[0]\n",
    "#s = np.where((TD['ref'] =='2003ApJ...593.1093L'))[0]\n",
    "\n",
    "s = np.where(TD['name_cat'].str.contains('ASR', na=False))[0]\n",
    "print(TD.loc[s, :])\n",
    "'''\n",
    "ra_ngc2264 = (6+41/60)*15\n",
    "dec_ngc2264 = (9+53/60)\n",
    "TD['sep_ngc2264'] = TD.apply(lambda row: SkyCoord(row.ra*u.deg, row.dec*u.deg, frame='icrs').separation(SkyCoord(ra_ngc2264*u.deg, dec_ngc2264*u.deg, frame='icrs')).arcsec, axis=1)\n",
    "s = np.where((TD['sep_ngc2264']<45*60))[0]\n",
    "\n",
    "\n",
    "ra_ic348 = (3+(44+33.2/60)/60)*15\n",
    "dec_ic348 = (32+9.8/60)\n",
    "print(ra_ic348,dec_ic348 )\n",
    "TD['sep_ic348'] = TD.apply(lambda row: SkyCoord(row.ra*u.deg, row.dec*u.deg, frame='icrs').separation(SkyCoord(ra_ic348*u.deg, dec_ic348*u.deg, frame='icrs')).arcsec, axis=1)\n",
    "s = np.where((TD['sep_ic348']<42*60))[0]\n",
    "'''\n",
    "ra_ngc1333 = (3+(29+11.3/60)/60)*15\n",
    "dec_ngc1333 = (31+(18+36/60)/60)\n",
    "print(ra_ngc1333,dec_ngc1333)\n",
    "TD['sep_ngc1333'] = TD.apply(lambda row: SkyCoord(row.ra*u.deg, row.dec*u.deg, frame='icrs').separation(SkyCoord(ra_ngc1333*u.deg, dec_ngc1333*u.deg, frame='icrs')).arcsec, axis=1)\n",
    "s = np.where((TD['sep_ngc1333']<6*60))[0]\n",
    "\n",
    "\n",
    "TD.loc[s, :].to_csv(f'{data_dir}/{field_name}_src_ambiguous.csv',index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove_code = 8: delete sources with ambiguous classifications\n",
      "Remove 13 [('CV', 1), ('HM-STAR', 3), ('HMXB', 1), ('LM-STAR', 3), ('LMXB', 2), ('YSO', 3)]\n",
      "Left 3207 [('AGN', 1484), ('CV', 57), ('HM-STAR', 120), ('HMXB', 44), ('LM-STAR', 264), ('LMXB', 56), ('NS', 101), ('NS_BIN', 25), ('YSO', 1056)]\n"
     ]
    }
   ],
   "source": [
    "print(\"remove_code = 8: delete sources with ambiguous classifications\")\n",
    "\n",
    "src_delete = ['[DWS84] 20', 'HD 38563 C', '[RHI84] 10- 632', '[HC2000] 114','[CHG2008] C2-18','Cl* NGC 2244 John 14','V* V2361 Ori','V* V1129 Cen','HD 35914','M 51 X-7','1E 161348-5055.1','XTE J1829-098']\n",
    "#ASR_notdelete = ['ASR 107', 'ASR 43', 'ASR 36']\n",
    "\n",
    "s = np.where( (TD['name_cat'].isin(src_delete)) | (TD['main_type'] == 'Candidate_YSO'))[0]# | (TD['name_cat'].str.contains('ASR', na=False) & (~TD['name_cat'].isin(ASR_notdelete)) ) )[0]\n",
    "TD.loc[s, 'remove_code'] = TD.loc[s, 'remove_code'] + 8\n",
    "\n",
    "print('Remove', len(s), sorted(Counter(TD.loc[s, 'Class']).items()))\n",
    "print('Left', len(TD[TD['remove_code']==0]), sorted(Counter(TD[TD['remove_code']==0]['Class']).items()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "TD.to_csv(f'{data_dir}/{field_name}.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TD = pd.read_csv(f'{data_dir}/{field_name}.csv')\n",
    "TD = TD[TD['remove_code']==0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3207 Counter({'AGN': 1484, 'YSO': 1056, 'LM-STAR': 264, 'HM-STAR': 120, 'NS': 101, 'CV': 57, 'LMXB': 56, 'HMXB': 44, 'NS_BIN': 25})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nCounter({'AGN': 1484, 'YSO': 1042, 'LM-STAR': 238, 'HM-STAR': 122, 'NS': 101, 'CV': 57, 'LMXB': 56, 'HMXB': 44, 'NS_BIN': 25})\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(len(TD),Counter(TD.Class))\n",
    "\n",
    "'''\n",
    "Counter({'AGN': 1484, 'YSO': 1042, 'LM-STAR': 238, 'HM-STAR': 122, 'NS': 101, 'CV': 57, 'LMXB': 56, 'HMXB': 44, 'NS_BIN': 25})\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_pers = create_perobs_data(TD, query_dir, data_dir, name_type='CSCview', name_col='name', ra_col='ra',dec_col='dec',coord_format='deg')\n",
    "\n",
    "df_pers.to_csv(f'{data_dir}/{field_name}_per.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 16046 per-obs data.\n",
      "Run add_newdata......\n",
      "Before adding new data:\n",
      "Run stats......\n",
      " H   M   S    #    %  \n",
      "--- --- --- ----- ----\n",
      "  Y   Y   Y 13128 81.8\n",
      "  Y   Y   N   867  5.4\n",
      "  N   Y   Y   304  1.8\n",
      "  Y   N   Y   248  1.5\n",
      "  N   Y   N    68  0.4\n",
      "  Y   N   N   377  2.3\n",
      "  N   N   Y   111  0.6\n",
      "  N   N   N   943  5.8\n",
      " ~Y   Y   Y  2918 18.1\n",
      "-----------------\n",
      "total:      16046\n",
      "Only  13128  detections have valid fluxes at all bands.\n",
      "After adding new  2289 s band data:\n",
      "Run stats......\n",
      " H   M   S    #    %  \n",
      "--- --- --- ----- ----\n",
      "  Y   Y   Y 13635 84.9\n",
      "  Y   Y   N   360  2.2\n",
      "  N   Y   Y   336  2.0\n",
      "  Y   N   Y   468  2.9\n",
      "  N   Y   N    36  0.2\n",
      "  Y   N   N   157  0.9\n",
      "  N   N   Y   229  1.4\n",
      "  N   N   N   825  5.1\n",
      " ~Y   Y   Y  2411 15.0\n",
      "-----------------\n",
      "total:      16046\n",
      "Only  13635  detections have valid fluxes at all bands.\n",
      "After adding new  1420 m band data:\n",
      "Run stats......\n",
      " H   M   S    #    %  \n",
      "--- --- --- ----- ----\n",
      "  Y   Y   Y 13938 86.8\n",
      "  Y   Y   N   361  2.2\n",
      "  N   Y   Y   475  2.9\n",
      "  Y   N   Y   165  1.0\n",
      "  N   Y   N    41  0.2\n",
      "  Y   N   N   156  0.9\n",
      "  N   N   Y    90  0.5\n",
      "  N   N   N   820  5.1\n",
      " ~Y   Y   Y  2108 13.1\n",
      "-----------------\n",
      "total:      16046\n",
      "Only  13938  detections have valid fluxes at all bands.\n",
      "After adding new  845 h band data:\n",
      "Run stats......\n",
      " H   M   S    #    %  \n",
      "--- --- --- ----- ----\n",
      "  Y   Y   Y 14232 88.6\n",
      "  Y   Y   N   368  2.2\n",
      "  N   Y   Y   181  1.1\n",
      "  Y   N   Y   191  1.1\n",
      "  N   Y   N    34  0.2\n",
      "  Y   N   N   157  0.9\n",
      "  N   N   Y    64  0.3\n",
      "  N   N   N   819  5.1\n",
      " ~Y   Y   Y  1814 11.3\n",
      "-----------------\n",
      "total:      16046\n",
      "Only  14232  detections have valid fluxes at all bands.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/orion51/Desktop/Research/MUWCLASS/MUWCLASS_CSCv2/codes/buildTD/../prepare_library.py:383: RuntimeWarning: All-NaN axis encountered\n",
      "  sig_max =  np.nanmax(df.loc[idx,sig])\n",
      "/home/orion51/Desktop/Research/MUWCLASS/MUWCLASS_CSCv2/codes/buildTD/../prepare_library.py:383: RuntimeWarning: All-NaN axis encountered\n",
      "  sig_max =  np.nanmax(df.loc[idx,sig])\n",
      "/home/orion51/Desktop/Research/MUWCLASS/MUWCLASS_CSCv2/codes/buildTD/../prepare_library.py:480: RuntimeWarning: All-NaN slice encountered\n",
      "  df_ave.loc[idx2, 'kp_prob_b_max'] = np.nanmax(df.loc[idx,'kp_prob_b'].values)\n",
      "/home/orion51/Desktop/Research/MUWCLASS/MUWCLASS_CSCv2/codes/buildTD/../prepare_library.py:480: RuntimeWarning: All-NaN slice encountered\n",
      "  df_ave.loc[idx2, 'kp_prob_b_max'] = np.nanmax(df.loc[idx,'kp_prob_b'].values)\n",
      "/home/orion51/Desktop/Research/MUWCLASS/MUWCLASS_CSCv2/codes/buildTD/../prepare_library.py:480: RuntimeWarning: All-NaN slice encountered\n",
      "  df_ave.loc[idx2, 'kp_prob_b_max'] = np.nanmax(df.loc[idx,'kp_prob_b'].values)\n",
      "/home/orion51/Desktop/Research/MUWCLASS/MUWCLASS_CSCv2/codes/buildTD/../prepare_library.py:480: RuntimeWarning: All-NaN slice encountered\n",
      "  df_ave.loc[idx2, 'kp_prob_b_max'] = np.nanmax(df.loc[idx,'kp_prob_b'].values)\n",
      "/home/orion51/Desktop/Research/MUWCLASS/MUWCLASS_CSCv2/codes/buildTD/../prepare_library.py:480: RuntimeWarning: All-NaN slice encountered\n",
      "  df_ave.loc[idx2, 'kp_prob_b_max'] = np.nanmax(df.loc[idx,'kp_prob_b'].values)\n",
      "/home/orion51/Desktop/Research/MUWCLASS/MUWCLASS_CSCv2/codes/buildTD/../prepare_library.py:481: RuntimeWarning: All-NaN slice encountered\n",
      "  df_ave.loc[idx2, 'significance_max'] = np.nanmax(df.loc[idx,'flux_significance_b'].values)\n",
      "/home/orion51/Desktop/Research/MUWCLASS/MUWCLASS_CSCv2/codes/buildTD/../prepare_library.py:480: RuntimeWarning: All-NaN slice encountered\n",
      "  df_ave.loc[idx2, 'kp_prob_b_max'] = np.nanmax(df.loc[idx,'kp_prob_b'].values)\n",
      "/home/orion51/Desktop/Research/MUWCLASS/MUWCLASS_CSCv2/codes/buildTD/../prepare_library.py:480: RuntimeWarning: All-NaN slice encountered\n",
      "  df_ave.loc[idx2, 'kp_prob_b_max'] = np.nanmax(df.loc[idx,'kp_prob_b'].values)\n",
      "/home/orion51/Desktop/Research/MUWCLASS/MUWCLASS_CSCv2/codes/buildTD/../prepare_library.py:480: RuntimeWarning: All-NaN slice encountered\n",
      "  df_ave.loc[idx2, 'kp_prob_b_max'] = np.nanmax(df.loc[idx,'kp_prob_b'].values)\n",
      "/home/orion51/Desktop/Research/MUWCLASS/MUWCLASS_CSCv2/codes/buildTD/../prepare_library.py:480: RuntimeWarning: All-NaN slice encountered\n",
      "  df_ave.loc[idx2, 'kp_prob_b_max'] = np.nanmax(df.loc[idx,'kp_prob_b'].values)\n",
      "/home/orion51/Desktop/Research/MUWCLASS/MUWCLASS_CSCv2/codes/buildTD/../prepare_library.py:480: RuntimeWarning: All-NaN slice encountered\n",
      "  df_ave.loc[idx2, 'kp_prob_b_max'] = np.nanmax(df.loc[idx,'kp_prob_b'].values)\n",
      "/home/orion51/Desktop/Research/MUWCLASS/MUWCLASS_CSCv2/codes/buildTD/../prepare_library.py:481: RuntimeWarning: All-NaN slice encountered\n",
      "  df_ave.loc[idx2, 'significance_max'] = np.nanmax(df.loc[idx,'flux_significance_b'].values)\n",
      "/home/orion51/Desktop/Research/MUWCLASS/MUWCLASS_CSCv2/codes/buildTD/../prepare_library.py:480: RuntimeWarning: All-NaN slice encountered\n",
      "  df_ave.loc[idx2, 'kp_prob_b_max'] = np.nanmax(df.loc[idx,'kp_prob_b'].values)\n",
      "/home/orion51/Desktop/Research/MUWCLASS/MUWCLASS_CSCv2/codes/buildTD/../prepare_library.py:480: RuntimeWarning: All-NaN slice encountered\n",
      "  df_ave.loc[idx2, 'kp_prob_b_max'] = np.nanmax(df.loc[idx,'kp_prob_b'].values)\n",
      "/home/orion51/Desktop/Research/MUWCLASS/MUWCLASS_CSCv2/codes/buildTD/../prepare_library.py:480: RuntimeWarning: All-NaN slice encountered\n",
      "  df_ave.loc[idx2, 'kp_prob_b_max'] = np.nanmax(df.loc[idx,'kp_prob_b'].values)\n",
      "/home/orion51/Desktop/Research/MUWCLASS/MUWCLASS_CSCv2/codes/buildTD/../prepare_library.py:480: RuntimeWarning: All-NaN slice encountered\n",
      "  df_ave.loc[idx2, 'kp_prob_b_max'] = np.nanmax(df.loc[idx,'kp_prob_b'].values)\n",
      "/home/orion51/Desktop/Research/MUWCLASS/MUWCLASS_CSCv2/codes/buildTD/../prepare_library.py:480: RuntimeWarning: All-NaN slice encountered\n",
      "  df_ave.loc[idx2, 'kp_prob_b_max'] = np.nanmax(df.loc[idx,'kp_prob_b'].values)\n",
      "/home/orion51/Desktop/Research/MUWCLASS/MUWCLASS_CSCv2/codes/buildTD/../prepare_library.py:480: RuntimeWarning: All-NaN slice encountered\n",
      "  df_ave.loc[idx2, 'kp_prob_b_max'] = np.nanmax(df.loc[idx,'kp_prob_b'].values)\n",
      "/home/orion51/Desktop/Research/MUWCLASS/MUWCLASS_CSCv2/codes/buildTD/../prepare_library.py:480: RuntimeWarning: All-NaN slice encountered\n",
      "  df_ave.loc[idx2, 'kp_prob_b_max'] = np.nanmax(df.loc[idx,'kp_prob_b'].values)\n",
      "/home/orion51/Desktop/Research/MUWCLASS/MUWCLASS_CSCv2/codes/buildTD/../prepare_library.py:480: RuntimeWarning: All-NaN slice encountered\n",
      "  df_ave.loc[idx2, 'kp_prob_b_max'] = np.nanmax(df.loc[idx,'kp_prob_b'].values)\n",
      "/home/orion51/Desktop/Research/MUWCLASS/MUWCLASS_CSCv2/codes/buildTD/../prepare_library.py:480: RuntimeWarning: All-NaN slice encountered\n",
      "  df_ave.loc[idx2, 'kp_prob_b_max'] = np.nanmax(df.loc[idx,'kp_prob_b'].values)\n",
      "/home/orion51/Desktop/Research/MUWCLASS/MUWCLASS_CSCv2/codes/buildTD/../prepare_library.py:480: RuntimeWarning: All-NaN slice encountered\n",
      "  df_ave.loc[idx2, 'kp_prob_b_max'] = np.nanmax(df.loc[idx,'kp_prob_b'].values)\n",
      "/home/orion51/Desktop/Research/MUWCLASS/MUWCLASS_CSCv2/codes/buildTD/../prepare_library.py:480: RuntimeWarning: All-NaN slice encountered\n",
      "  df_ave.loc[idx2, 'kp_prob_b_max'] = np.nanmax(df.loc[idx,'kp_prob_b'].values)\n",
      "/home/orion51/Desktop/Research/MUWCLASS/MUWCLASS_CSCv2/codes/buildTD/../prepare_library.py:480: RuntimeWarning: All-NaN slice encountered\n",
      "  df_ave.loc[idx2, 'kp_prob_b_max'] = np.nanmax(df.loc[idx,'kp_prob_b'].values)\n",
      "/home/orion51/Desktop/Research/MUWCLASS/MUWCLASS_CSCv2/codes/buildTD/../prepare_library.py:480: RuntimeWarning: All-NaN slice encountered\n",
      "  df_ave.loc[idx2, 'kp_prob_b_max'] = np.nanmax(df.loc[idx,'kp_prob_b'].values)\n",
      "/home/orion51/Desktop/Research/MUWCLASS/MUWCLASS_CSCv2/codes/buildTD/../prepare_library.py:480: RuntimeWarning: All-NaN slice encountered\n",
      "  df_ave.loc[idx2, 'kp_prob_b_max'] = np.nanmax(df.loc[idx,'kp_prob_b'].values)\n",
      "/home/orion51/Desktop/Research/MUWCLASS/MUWCLASS_CSCv2/codes/buildTD/../prepare_library.py:480: RuntimeWarning: All-NaN slice encountered\n",
      "  df_ave.loc[idx2, 'kp_prob_b_max'] = np.nanmax(df.loc[idx,'kp_prob_b'].values)\n",
      "/home/orion51/Desktop/Research/MUWCLASS/MUWCLASS_CSCv2/codes/buildTD/../prepare_library.py:480: RuntimeWarning: All-NaN slice encountered\n",
      "  df_ave.loc[idx2, 'kp_prob_b_max'] = np.nanmax(df.loc[idx,'kp_prob_b'].values)\n",
      "/home/orion51/Desktop/Research/MUWCLASS/MUWCLASS_CSCv2/codes/buildTD/../prepare_library.py:481: RuntimeWarning: All-NaN slice encountered\n",
      "  df_ave.loc[idx2, 'significance_max'] = np.nanmax(df.loc[idx,'flux_significance_b'].values)\n",
      "/home/orion51/Desktop/Research/MUWCLASS/MUWCLASS_CSCv2/codes/buildTD/../prepare_library.py:481: RuntimeWarning: All-NaN slice encountered\n",
      "  df_ave.loc[idx2, 'significance_max'] = np.nanmax(df.loc[idx,'flux_significance_b'].values)\n",
      "/home/orion51/Desktop/Research/MUWCLASS/MUWCLASS_CSCv2/codes/buildTD/../prepare_library.py:480: RuntimeWarning: All-NaN slice encountered\n",
      "  df_ave.loc[idx2, 'kp_prob_b_max'] = np.nanmax(df.loc[idx,'kp_prob_b'].values)\n",
      "/home/orion51/Desktop/Research/MUWCLASS/MUWCLASS_CSCv2/codes/buildTD/../prepare_library.py:480: RuntimeWarning: All-NaN slice encountered\n",
      "  df_ave.loc[idx2, 'kp_prob_b_max'] = np.nanmax(df.loc[idx,'kp_prob_b'].values)\n",
      "/home/orion51/Desktop/Research/MUWCLASS/MUWCLASS_CSCv2/codes/buildTD/../prepare_library.py:480: RuntimeWarning: All-NaN slice encountered\n",
      "  df_ave.loc[idx2, 'kp_prob_b_max'] = np.nanmax(df.loc[idx,'kp_prob_b'].values)\n",
      "/home/orion51/Desktop/Research/MUWCLASS/MUWCLASS_CSCv2/codes/buildTD/../prepare_library.py:480: RuntimeWarning: All-NaN slice encountered\n",
      "  df_ave.loc[idx2, 'kp_prob_b_max'] = np.nanmax(df.loc[idx,'kp_prob_b'].values)\n",
      "/home/orion51/Desktop/Research/MUWCLASS/MUWCLASS_CSCv2/codes/buildTD/../prepare_library.py:480: RuntimeWarning: All-NaN slice encountered\n",
      "  df_ave.loc[idx2, 'kp_prob_b_max'] = np.nanmax(df.loc[idx,'kp_prob_b'].values)\n",
      "/home/orion51/Desktop/Research/MUWCLASS/MUWCLASS_CSCv2/codes/buildTD/../prepare_library.py:480: RuntimeWarning: All-NaN slice encountered\n",
      "  df_ave.loc[idx2, 'kp_prob_b_max'] = np.nanmax(df.loc[idx,'kp_prob_b'].values)\n",
      "/home/orion51/Desktop/Research/MUWCLASS/MUWCLASS_CSCv2/codes/buildTD/../prepare_library.py:480: RuntimeWarning: All-NaN slice encountered\n",
      "  df_ave.loc[idx2, 'kp_prob_b_max'] = np.nanmax(df.loc[idx,'kp_prob_b'].values)\n",
      "/home/orion51/Desktop/Research/MUWCLASS/MUWCLASS_CSCv2/codes/buildTD/../prepare_library.py:480: RuntimeWarning: All-NaN slice encountered\n",
      "  df_ave.loc[idx2, 'kp_prob_b_max'] = np.nanmax(df.loc[idx,'kp_prob_b'].values)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/orion51/Desktop/Research/MUWCLASS/MUWCLASS_CSCv2/codes/buildTD/../prepare_library.py:480: RuntimeWarning: All-NaN slice encountered\n",
      "  df_ave.loc[idx2, 'kp_prob_b_max'] = np.nanmax(df.loc[idx,'kp_prob_b'].values)\n",
      "/home/orion51/Desktop/Research/MUWCLASS/MUWCLASS_CSCv2/codes/buildTD/../prepare_library.py:480: RuntimeWarning: All-NaN slice encountered\n",
      "  df_ave.loc[idx2, 'kp_prob_b_max'] = np.nanmax(df.loc[idx,'kp_prob_b'].values)\n",
      "/home/orion51/Desktop/Research/MUWCLASS/MUWCLASS_CSCv2/codes/buildTD/../prepare_library.py:480: RuntimeWarning: All-NaN slice encountered\n",
      "  df_ave.loc[idx2, 'kp_prob_b_max'] = np.nanmax(df.loc[idx,'kp_prob_b'].values)\n",
      "/home/orion51/Desktop/Research/MUWCLASS/MUWCLASS_CSCv2/codes/buildTD/../prepare_library.py:480: RuntimeWarning: All-NaN slice encountered\n",
      "  df_ave.loc[idx2, 'kp_prob_b_max'] = np.nanmax(df.loc[idx,'kp_prob_b'].values)\n",
      "/home/orion51/Desktop/Research/MUWCLASS/MUWCLASS_CSCv2/codes/buildTD/../prepare_library.py:480: RuntimeWarning: All-NaN slice encountered\n",
      "  df_ave.loc[idx2, 'kp_prob_b_max'] = np.nanmax(df.loc[idx,'kp_prob_b'].values)\n",
      "/home/orion51/Desktop/Research/MUWCLASS/MUWCLASS_CSCv2/codes/buildTD/../prepare_library.py:480: RuntimeWarning: All-NaN slice encountered\n",
      "  df_ave.loc[idx2, 'kp_prob_b_max'] = np.nanmax(df.loc[idx,'kp_prob_b'].values)\n",
      "/home/orion51/Desktop/Research/MUWCLASS/MUWCLASS_CSCv2/codes/buildTD/../prepare_library.py:480: RuntimeWarning: All-NaN slice encountered\n",
      "  df_ave.loc[idx2, 'kp_prob_b_max'] = np.nanmax(df.loc[idx,'kp_prob_b'].values)\n",
      "/home/orion51/Desktop/Research/MUWCLASS/MUWCLASS_CSCv2/codes/buildTD/../prepare_library.py:480: RuntimeWarning: All-NaN slice encountered\n",
      "  df_ave.loc[idx2, 'kp_prob_b_max'] = np.nanmax(df.loc[idx,'kp_prob_b'].values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'AGN': 1390, 'YSO': 1038, 'LM-STAR': 243, 'HM-STAR': 117, 'NS': 87, 'CV': 44, 'LMXB': 42, 'HMXB': 26, 'NS_BIN': 25})\n"
     ]
    }
   ],
   "source": [
    "df_pers = pd.read_csv(f'{data_dir}/{field_name}_per.csv', low_memory=False)\n",
    "\n",
    "df_pers['name'] = df_pers['name'].str.lstrip()\n",
    "df_pers['per_remove_code'] = 0\n",
    "\n",
    "df_ave, df_obs = cal_ave(df_pers, data_dir, dtype='TD',Chandratype='CSC',verb=verb)\n",
    "\n",
    "#df_ave.update(TD)\n",
    "#df_ave = pd.concat([df_ave, TD.iloc[:, np.r_[:8, 14:16, 24]]], axis=1)\n",
    "#print(df_ave.columns)\n",
    "df_ave = pd.merge(df_ave, TD.iloc[:, np.r_[:9, 14:16, 24]], how='inner', on='name')\n",
    "#df_ave = df_ave.rename(columns={'main_type':'main_type_simbad'})\n",
    "print(Counter(df_ave.Class))\n",
    "df_ave.to_csv(f'{data_dir}/{field_name}_ave.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3012 Counter({'AGN': 1390, 'YSO': 1038, 'LM-STAR': 243, 'HM-STAR': 117, 'NS': 87, 'CV': 44, 'LMXB': 42, 'HMXB': 26, 'NS_BIN': 25})\n"
     ]
    }
   ],
   "source": [
    "print(len(df_ave),Counter(df_ave['Class']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15547657012939453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/orion51/Desktop/Research/MUWCLASS/MUWCLASS_CSCv2/codes/buildTD/../prepare_library.py:867: DtypeWarning: Columns (9,10,12,314,315,316,317) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data_MW_old = pd.read_csv(f'{file_dir}/{field_name}_MW.csv')\n"
     ]
    }
   ],
   "source": [
    "#'''\n",
    "df_ave = pd.read_csv(f'{data_dir}/{field_name}_ave.csv')\n",
    "\n",
    "# cross-match with MW catalogs\n",
    "start = time.time()\n",
    "add_MW(df_ave, data_dir, field_name, Chandratype='CSC')\n",
    "end = time.time() \n",
    "print(end - start)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27394/1867843281.py:1: DtypeWarning: Columns (9,10,12,314,315,316,317) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_MW = pd.read_csv(f'{data_dir}/{field_name}_MW.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2275 counterparts matched for gaia\n",
      "1854 counterparts matched for 2mass\n",
      "1909 counterparts matched for catwise\n",
      "2117 counterparts matched for unwise\n",
      "1810 counterparts matched for allwise\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27394/1867843281.py:12: DtypeWarning: Columns (9,10,12,314,315,316,317) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_MW_cf = pd.read_csv(f'{data_dir}/{field_name}_MW_clean.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('LMXB', 1), ('NS_BIN', 1)]\n",
      "[('AGN', 1390), ('CV', 44), ('HM-STAR', 117), ('HMXB', 26), ('LM-STAR', 243), ('LMXB', 41), ('NS', 87), ('NS_BIN', 24), ('YSO', 1038)]\n",
      "Final breakdown 3002 Counter({'AGN': 1390, 'YSO': 1038, 'LM-STAR': 236, 'HM-STAR': 116, 'NS': 87, 'CV': 44, 'LMXB': 41, 'HMXB': 26, 'NS_BIN': 24})\n"
     ]
    }
   ],
   "source": [
    "df_MW = pd.read_csv(f'{data_dir}/{field_name}_MW.csv')\n",
    "\n",
    "#df_MW['PU_max'] = df_MW[['sep', 'err_ellipse_r0']].max(axis=1)\n",
    "df_MW.loc[df_MW.name == '2CXO J182615.0-145055', 'err_ellipse_r0'] = 1.2 \n",
    "\n",
    "df_MW_cf = confusion_clean(df_MW,X_PU='err_ellipse_r0',Chandratype='CSC')\n",
    "df_MW_cf.to_csv(f'{data_dir}/{field_name}_MW_clean.csv',index=False)\n",
    "#'''\n",
    "\n",
    "#df_ave = pd.concat([df_MW, TD.iloc[:, np.r_[:8]]], axis=1)\n",
    "\n",
    "df_MW_cf = pd.read_csv(f'{data_dir}/{field_name}_MW_clean.csv')\n",
    "df_ave = TD_clean(df_MW_cf, remove_codes = [1, 32]) # previousl no remove_codes =2?!\n",
    "\n",
    "s_remove = np.where(df_ave.name_cat.isin(['Mon R2- 5b','Cl* NGC 2264    SBL    1025B','** RAT   17A','NGC 6611 374','NGC 6611 245','NGC 6611 213','2MASS J13121845-6237309','V* V700 Per','ESO-HA 1171', 'VSS II- 7']))[0]\n",
    "\n",
    "df_ave.loc[s_remove, 'remove_code'] = df_ave.loc[s_remove, 'remove_code']+128\n",
    "\n",
    "df_ave.to_csv(f'{data_dir}/{field_name}_MW_before_remove.csv', index=False)\n",
    "\n",
    "df_remove = df_ave[df_ave['remove_code']==0].reset_index(drop=True)\n",
    "print('Final breakdown', len(df_remove), Counter(df_remove['Class']))\n",
    "#df_remove_cols = ['name_cat','ra_cat','dec_cat','error','Class','SubClass','ref','remove_code','sep','name','ra','dec','err_ellipse_r0','err_ellipse_r1','err_ellipse_ang','significance\tflux_aper_b\tflux_aper_h\tflux_aper_m\tflux_aper_s\tks_intra_prob_b\tkp_intra_prob_b\tvar_inter_prob_b\tGmag\tBPmag\tRPmag\tpm_gaia\tpmRA_gaia\tpmDE_gaia\tJmag\tHmag\tKmag\tW1mag_catwise\tW2mag_catwise\tpmRA_catwise\tpmDE_catwise\tW1mag_allwise\tW2mag_allwise\tW3mag_allwise\tW4mag_allwise\trgeo\trpgeo\tmain_id\tmain_type\tW1mag_unwise\tW2mag_unwise\tW1mag_comb\tW2mag_comb\tCSC_flags]\n",
    "df_remove.to_csv(f'{data_dir}/{field_name}_MW_remove.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3012 Counter({'AGN': 1390, 'YSO': 1038, 'LM-STAR': 243, 'HM-STAR': 117, 'NS': 87, 'CV': 44, 'LMXB': 42, 'HMXB': 26, 'NS_BIN': 25})\n",
      "Counter({0: 3002, 128: 8, 32: 1, 33: 1})\n"
     ]
    }
   ],
   "source": [
    "print(len(df_MW_cf),Counter(df_MW_cf['Class']))\n",
    "\n",
    "print(Counter(df_ave['remove_code']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove 25 [('LM-STAR', 4), ('YSO', 21)]\n",
      "Final breakdown 2977 [('AGN', 1390), ('CV', 44), ('HM-STAR', 116), ('HMXB', 26), ('LM-STAR', 232), ('LMXB', 41), ('NS', 87), ('NS_BIN', 24), ('YSO', 1017)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27394/2732927376.py:1: DtypeWarning: Columns (314,315,316,317) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f'{data_dir}/{field_name}_MW_remove.csv')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(f'{data_dir}/{field_name}_MW_remove.csv')\n",
    "df_final = prepare_cols(df, cp_thres=0, vphas=False,gaiadata=False,cp_conf_flag=False, TD=True, NS_MWdrop=False, STAR_classremove=['HM-STAR','LM-STAR','YSO'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>PU</th>\n",
       "      <th>significance</th>\n",
       "      <th>Fcsc_s</th>\n",
       "      <th>e_Fcsc_s</th>\n",
       "      <th>Fcsc_m</th>\n",
       "      <th>e_Fcsc_m</th>\n",
       "      <th>Fcsc_h</th>\n",
       "      <th>...</th>\n",
       "      <th>W4mag</th>\n",
       "      <th>e_W4mag</th>\n",
       "      <th>cp_flag_allwise</th>\n",
       "      <th>Class</th>\n",
       "      <th>cp_flag_wise12</th>\n",
       "      <th>which_wise12</th>\n",
       "      <th>W1mag</th>\n",
       "      <th>e_W1mag</th>\n",
       "      <th>W2mag</th>\n",
       "      <th>e_W2mag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2CXO J000009.3+135618</td>\n",
       "      <td>0.039125</td>\n",
       "      <td>13.938494</td>\n",
       "      <td>0.79</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.671074e-15</td>\n",
       "      <td>1.098049e-15</td>\n",
       "      <td>4.844000e-16</td>\n",
       "      <td>4.844000e-16</td>\n",
       "      <td>1.989924e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>8.827</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0</td>\n",
       "      <td>AGN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>allwise</td>\n",
       "      <td>15.489</td>\n",
       "      <td>0.045</td>\n",
       "      <td>14.605</td>\n",
       "      <td>0.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2CXO J000230.7+004959</td>\n",
       "      <td>0.627958</td>\n",
       "      <td>0.833072</td>\n",
       "      <td>0.72</td>\n",
       "      <td>11.07</td>\n",
       "      <td>5.675297e-14</td>\n",
       "      <td>6.911736e-15</td>\n",
       "      <td>2.874798e-14</td>\n",
       "      <td>5.285001e-15</td>\n",
       "      <td>5.735159e-14</td>\n",
       "      <td>...</td>\n",
       "      <td>7.915</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0</td>\n",
       "      <td>AGN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>allwise</td>\n",
       "      <td>14.497</td>\n",
       "      <td>0.030</td>\n",
       "      <td>13.178</td>\n",
       "      <td>0.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2CXO J000622.6-000424</td>\n",
       "      <td>1.594333</td>\n",
       "      <td>-0.073572</td>\n",
       "      <td>0.78</td>\n",
       "      <td>25.42</td>\n",
       "      <td>1.544000e-13</td>\n",
       "      <td>1.220000e-14</td>\n",
       "      <td>1.165798e-13</td>\n",
       "      <td>7.650074e-15</td>\n",
       "      <td>4.038000e-13</td>\n",
       "      <td>...</td>\n",
       "      <td>8.398</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>AGN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>allwise</td>\n",
       "      <td>15.299</td>\n",
       "      <td>0.041</td>\n",
       "      <td>14.245</td>\n",
       "      <td>0.049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2CXO J000659.2-001740</td>\n",
       "      <td>1.747042</td>\n",
       "      <td>-0.294661</td>\n",
       "      <td>0.84</td>\n",
       "      <td>4.11</td>\n",
       "      <td>1.069845e-14</td>\n",
       "      <td>3.658216e-15</td>\n",
       "      <td>6.211934e-15</td>\n",
       "      <td>2.773510e-15</td>\n",
       "      <td>1.372718e-14</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-8</td>\n",
       "      <td>AGN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>catwise</td>\n",
       "      <td>16.549</td>\n",
       "      <td>0.037</td>\n",
       "      <td>15.650</td>\n",
       "      <td>0.057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2CXO J000703.6+155423</td>\n",
       "      <td>1.765000</td>\n",
       "      <td>15.906575</td>\n",
       "      <td>0.72</td>\n",
       "      <td>8.63</td>\n",
       "      <td>4.660000e-15</td>\n",
       "      <td>2.824000e-15</td>\n",
       "      <td>1.593202e-14</td>\n",
       "      <td>5.625001e-15</td>\n",
       "      <td>5.350000e-13</td>\n",
       "      <td>...</td>\n",
       "      <td>5.208</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0</td>\n",
       "      <td>AGN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>allwise</td>\n",
       "      <td>11.610</td>\n",
       "      <td>0.023</td>\n",
       "      <td>10.588</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    name        ra        dec    PU  significance  \\\n",
       "0  2CXO J000009.3+135618  0.039125  13.938494  0.79          1.95   \n",
       "1  2CXO J000230.7+004959  0.627958   0.833072  0.72         11.07   \n",
       "2  2CXO J000622.6-000424  1.594333  -0.073572  0.78         25.42   \n",
       "3  2CXO J000659.2-001740  1.747042  -0.294661  0.84          4.11   \n",
       "4  2CXO J000703.6+155423  1.765000  15.906575  0.72          8.63   \n",
       "\n",
       "         Fcsc_s      e_Fcsc_s        Fcsc_m      e_Fcsc_m        Fcsc_h  ...  \\\n",
       "0  1.671074e-15  1.098049e-15  4.844000e-16  4.844000e-16  1.989924e-15  ...   \n",
       "1  5.675297e-14  6.911736e-15  2.874798e-14  5.285001e-15  5.735159e-14  ...   \n",
       "2  1.544000e-13  1.220000e-14  1.165798e-13  7.650074e-15  4.038000e-13  ...   \n",
       "3  1.069845e-14  3.658216e-15  6.211934e-15  2.773510e-15  1.372718e-14  ...   \n",
       "4  4.660000e-15  2.824000e-15  1.593202e-14  5.625001e-15  5.350000e-13  ...   \n",
       "\n",
       "   W4mag  e_W4mag  cp_flag_allwise  Class  cp_flag_wise12 which_wise12  \\\n",
       "0  8.827    0.462                0    AGN             0.0      allwise   \n",
       "1  7.915    0.235                0    AGN             0.0      allwise   \n",
       "2  8.398      NaN                0    AGN             0.0      allwise   \n",
       "3    NaN      NaN               -8    AGN             0.0      catwise   \n",
       "4  5.208    0.039                0    AGN             0.0      allwise   \n",
       "\n",
       "    W1mag  e_W1mag   W2mag  e_W2mag  \n",
       "0  15.489    0.045  14.605    0.059  \n",
       "1  14.497    0.030  13.178    0.031  \n",
       "2  15.299    0.041  14.245    0.049  \n",
       "3  16.549    0.037  15.650    0.057  \n",
       "4  11.610    0.023  10.588    0.021  \n",
       "\n",
       "[5 rows x 72 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove 21 [('LM-STAR', 1), ('YSO', 20)]\n",
      "Final breakdown 2941 [('AGN', 1390), ('CV', 44), ('HM-STAR', 118), ('HMXB', 26), ('LM-STAR', 207), ('LMXB', 41), ('NS', 87), ('NS_BIN', 24), ('YSO', 1004)]\n",
      "2941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27394/2215806354.py:1: DtypeWarning: Columns (314,315,316,317) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  TD_0224 = pd.read_csv('../../files/CSC_TD_v5_02242022_MW_remove.csv')\n"
     ]
    }
   ],
   "source": [
    "TD_0224 = pd.read_csv('../../files/CSC_TD_v5_02242022_MW_remove.csv')\n",
    "TD_0224 = prepare_cols(TD_0224, cp_thres=0, vphas=False,gaiadata=False,cp_conf_flag=False, TD=True, NS_MWdrop=False, STAR_classremove=['HM-STAR','LM-STAR','YSO'])\n",
    "\n",
    "print(len(TD_0224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2929\n",
      "                       name    Class\n",
      "1443  2CXO J022608.5+620647      YSO\n",
      "1446  2CXO J022715.6+613730  HM-STAR\n",
      "1484  2CXO J104517.2-594701  HM-STAR\n",
      "1485  2CXO J104530.2-594820  HM-STAR\n",
      "1486  2CXO J104536.7-594702  HM-STAR\n",
      "1505  2CXO J111901.6-613106  HM-STAR\n",
      "1509  2CXO J165410.7-414747      YSO\n",
      "1510  2CXO J165414.7-415111      YSO\n",
      "1511  2CXO J165418.1-415016      YSO\n",
      "1521  2CXO J182022.6-160833      YSO\n",
      "1673  2CXO J053509.8-052338      YSO\n",
      "1675  2CXO J053510.5-052216      YSO\n",
      "1676  2CXO J053510.8-052240  LM-STAR\n",
      "1677  2CXO J053510.9-052224  LM-STAR\n",
      "1679  2CXO J053512.9-052457  LM-STAR\n",
      "1680  2CXO J053513.1-052452  LM-STAR\n",
      "1682  2CXO J053513.9-052319      YSO\n",
      "1683  2CXO J053514.8-052315  LM-STAR\n",
      "1685  2CXO J053515.0-052354  LM-STAR\n",
      "1686  2CXO J053515.2-052318      YSO\n",
      "1687  2CXO J053515.5-052337      YSO\n",
      "1688  2CXO J053515.7-052411  LM-STAR\n",
      "1689  2CXO J053515.7-052424  LM-STAR\n",
      "1692  2CXO J053516.7-052316      YSO\n",
      "1693  2CXO J053517.5-052324      YSO\n",
      "1694  2CXO J053517.8-052440      YSO\n",
      "1695  2CXO J053517.8-052430  LM-STAR\n",
      "1696  2CXO J053518.2-052430      YSO\n",
      "1698  2CXO J053518.9-052321  LM-STAR\n",
      "1699  2CXO J053519.1-052234  LM-STAR\n",
      "1701  2CXO J053520.5-052140  LM-STAR\n",
      "1702  2CXO J053520.6-052510  LM-STAR\n",
      "1703  2CXO J053521.0-052355  LM-STAR\n",
      "1705  2CXO J053521.7-052348  LM-STAR\n",
      "1707  2CXO J053522.0-052432      YSO\n",
      "1709  2CXO J053522.6-052137  LM-STAR\n",
      "1710  2CXO J053522.6-052140  LM-STAR\n",
      "1711  2CXO J053522.7-052157  LM-STAR\n",
      "1713  2CXO J053524.9-052401  LM-STAR\n",
      "1715  2CXO J053525.3-052345  LM-STAR\n",
      "1716  2CXO J053525.4-052333  LM-STAR\n",
      "1717  2CXO J053526.1-052539  LM-STAR\n",
      "1720  2CXO J053527.7-052332  LM-STAR\n",
      "1721  2CXO J053527.8-052323      YSO\n",
      "1819  2CXO J102402.2-574502      YSO\n",
      "1897  2CXO J165423.2-414855      YSO\n",
      "1911  2CXO J190139.3-370207  LM-STAR\n",
      "2941  2CXO J111204.0-604038      YSO\n",
      "                       name    Class\n",
      "1446  2CXO J023247.5+612700      YSO\n",
      "1447  2CXO J023249.3+612641      YSO\n",
      "1480  2CXO J104359.8-593524  HM-STAR\n",
      "1513  2CXO J181838.1-134425      YSO\n",
      "1528  2CXO J203149.6+412826  HM-STAR\n",
      "1534  2CXO J203234.8+405617  HM-STAR\n",
      "1547  2CXO J203313.6+411305  HM-STAR\n",
      "1553  2CXO J203321.0+411740  HM-STAR\n",
      "1557  2CXO J203330.2+413557  HM-STAR\n",
      "1564  2CXO J203416.0+410219  HM-STAR\n",
      "1679  2CXO J053520.1-052308      YSO\n",
      "1857  2CXO J162825.1-244501      YSO\n",
      "2929\n",
      "                       name  Class_x Class_y\n",
      "1634  2CXO J042200.7+265732  LM-STAR     YSO\n"
     ]
    }
   ],
   "source": [
    "print(len(df_final[df_final.name.isin(TD_0224.name)]))\n",
    "#print(len(TD_0224[TD_0224.name.isin(df_final.name)]))\n",
    "print(df_final.loc[~df_final.name.isin(TD_0224.name), ['name','Class']])\n",
    "print(TD_0224.loc[~TD_0224.name.isin(df_final.name), ['name','Class']])\n",
    "\n",
    "TD_comb = pd.merge(df_final, TD_0224, on='name', how='inner')\n",
    "print(len(TD_comb))\n",
    "print(TD_comb.loc[TD_comb.Class_x != TD_comb.Class_y, ['name','Class_x','Class_y']])\n",
    "#print(TD_0224.loc[(TD_0224.name.isin(df_final.name) & (TD_0224.Class == df_final.Class), ['name','Class']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
